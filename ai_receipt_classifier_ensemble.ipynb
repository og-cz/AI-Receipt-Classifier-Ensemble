{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bco1KMEc-A3"
      },
      "source": [
        "# AI Receipt Classifier Ensemble\n",
        "\n",
        "This notebook implements a hybrid ML pipeline that extracts features from receipts using pretrained CNNs (ResNet34, EfficientNet-B0, MobileNetV2), trains XGBoost classifiers on these features, and combines their predictions via soft-voting to accurately detect whether a receipt is real or AI-generated, with evaluation metrics and single-image inference included."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Machine Learning Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KwOAY-p2oQt",
        "outputId": "7e0b6eea-e35c-43de-85b8-27fd54ad40e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cpu)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.24)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.7.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.29.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.12/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2->seaborn) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2026.1.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision timm xgboost scikit-learn matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lb2n5no1cwVl"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import timm\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCSHabiwc9ig"
      },
      "source": [
        "# Define dataset path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gseXEdCAdIXp",
        "outputId": "b483bad2-fbbb-49c0-c770-7c4d3110e8ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/ INPUT DRIVE LOCATION\"\n",
        "folders = [\"clean-total-legit\", \"clean-total-ai\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVK_oYgqyVvh",
        "outputId": "25393316-02a8-40d7-9051-4755416e1bb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cleaned-data exists: True\n",
            "Folders inside cleaned-data: ['clean-total-legit', 'clean-total-ai', 'eveyrthing-must-be-jpg.txt']\n"
          ]
        }
      ],
      "source": [
        "print(\"cleaned-data exists:\", os.path.exists(dataset_path))\n",
        "print(\"Folders inside cleaned-data:\", os.listdir(dataset_path))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKBcFc9ddIEJ"
      },
      "source": [
        "#  Image preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meSm4b2ldQNV"
      },
      "outputs": [],
      "source": [
        "image_size = 224  # standard input size\n",
        "transform = transforms.Compose([\n",
        "  transforms.Resize((image_size, image_size)),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                        [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IcoirH7dWqv"
      },
      "source": [
        "# Load dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9t08JRodW3Q",
        "outputId": "036920f9-dc9c-4b5f-cc92-9f5432cf43b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total images: 736\n"
          ]
        }
      ],
      "source": [
        "# Create a unified dataset with labels: 0 = legit, 1 = AI\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for idx, folder in enumerate(folders):\n",
        "    folder_path = os.path.join(dataset_path, folder)\n",
        "    for img_file in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, img_file)\n",
        "        data.append(img_path)\n",
        "        labels.append(idx)\n",
        "\n",
        "print(f\"Total images: {len(data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ovoiTQ5zDoF",
        "outputId": "3a5abd07-28e9-43b7-e5a9-9ee6d6e278fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples: 588\n",
            "Test samples: 148\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "labels = np.array(labels)\n",
        "\n",
        "data_train, data_test, y_train, y_test = train_test_split(\n",
        "    data,\n",
        "    labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=labels\n",
        ")\n",
        "\n",
        "print(\"Training samples:\", len(data_train))\n",
        "print(\"Test samples:\", len(data_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgrJCXlHdY8C"
      },
      "source": [
        "# Helper function: load and preprocess image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AAtjb39dZH9"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def load_image(path):\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    return transform(img).unsqueeze(0)  # add batch dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFUQ1UuNdcw5"
      },
      "source": [
        "#  Define CNN models (pretrained)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHp7UF9zdcVv",
        "outputId": "afd3e765-c119-4571-899c-782d9f3ad7d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 249MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 159MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 110MB/s] \n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "cnn_models = {\n",
        "    \"resnet34\": models.resnet34(pretrained=True),\n",
        "    \"efficientnet_b0\": models.efficientnet_b0(pretrained=True),\n",
        "    \"mobilenet_v2\": models.mobilenet_v2(pretrained=True)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXNDYWN5dft7"
      },
      "outputs": [],
      "source": [
        "# Remove final classifier layers, keep feature extractor\n",
        "for name, model in cnn_models.items():\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    if \"resnet\" in name:\n",
        "        cnn_models[name] = nn.Sequential(*list(model.children())[:-1])\n",
        "    elif \"efficientnet\" in name or \"mobilenet\" in name:\n",
        "        cnn_models[name] = nn.Sequential(*list(model.children())[:-1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E9mz3Tddir-"
      },
      "source": [
        "# Extract features for all images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8F1xAKb9diz4"
      },
      "outputs": [],
      "source": [
        "def extract_features(model, data):\n",
        "    features = []\n",
        "    with torch.no_grad():\n",
        "        for path in data:\n",
        "            img_tensor = load_image(path).to(device)\n",
        "            feat = model(img_tensor)\n",
        "            feat = feat.view(feat.size(0), -1)  # flatten\n",
        "            features.append(feat.cpu().numpy()[0])\n",
        "    return np.array(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xqs2Y0oBzqAZ",
        "outputId": "b1861a9e-e6a6-41e7-8656-ad0be14c656b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting features from resnet34...\n",
            "Extracting features from efficientnet_b0...\n",
            "Extracting features from mobilenet_v2...\n"
          ]
        }
      ],
      "source": [
        "features_train_dict = {}\n",
        "features_test_dict = {}\n",
        "\n",
        "for name, model in cnn_models.items():\n",
        "    print(f\"Extracting features from {name}...\")\n",
        "    features_train_dict[name] = extract_features(model, data_train)\n",
        "    features_test_dict[name] = extract_features(model, data_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4JiGy-dedyi"
      },
      "source": [
        "# Train XGBoost classifier per model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q287a9TneeDi",
        "outputId": "3737d019-e95a-4221-b0aa-74466b81a796"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training XGBoost for resnet34 features...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [13:42:10] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training XGBoost for efficientnet_b0 features...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [13:42:11] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training XGBoost for mobilenet_v2 features...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [13:42:25] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "xgb_models = {}\n",
        "\n",
        "for name in cnn_models.keys():\n",
        "    print(f\"Training XGBoost for {name} features...\")\n",
        "    model = xgb.XGBClassifier(\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='logloss',\n",
        "        scale_pos_weight=1  # optional: handle imbalance\n",
        "    )\n",
        "    model.fit(features_train_dict[name], y_train)  # train on train features\n",
        "    xgb_models[name] = model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Hx9E_4Heg_7"
      },
      "source": [
        "# Ensemble prediction (soft voting)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8XKGA_2egp9"
      },
      "outputs": [],
      "source": [
        "# Initialize array to hold summed probabilities\n",
        "probs = np.zeros((len(y_test), 2))  # 2 classes: real vs AI/fake\n",
        "\n",
        "# Add probabilities from each XGBoost model\n",
        "for name, model in xgb_models.items():\n",
        "    probs += model.predict_proba(features_test_dict[name])  # use test features\n",
        "\n",
        "# Average probabilities\n",
        "probs /= len(xgb_models)\n",
        "\n",
        "# Final predicted labels\n",
        "y_pred = np.argmax(probs, axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_OYUoloekG-"
      },
      "source": [
        "# Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "k0bBKYUBekSv",
        "outputId": "08beaf9c-9706-4129-afce-197be4e54e09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensemble Accuracy: 99.32%\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Real       1.00      0.99      0.99        80\n",
            "     AI/Fake       0.99      1.00      0.99        68\n",
            "\n",
            "    accuracy                           0.99       148\n",
            "   macro avg       0.99      0.99      0.99       148\n",
            "weighted avg       0.99      0.99      0.99       148\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Accuracy\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Ensemble Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Real', 'AI'], yticklabels=['Real', 'AI'])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "# Classification Report\n",
        "print(classification_report(y_test, y_pred, target_names=['Real', 'AI/Fake']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TotHMcU33NCf"
      },
      "source": [
        "# TRY AND UPLOAD NEW PHOTO\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stwLsMXc3MT6",
        "outputId": "97fd58af-712e-44cc-ad3b-eeea1c7817f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction for /content/drive/MyDrive/ML-Samples/try-test/03.jpg: AI/Fake\n",
            "Probabilities - Real: 0.00, AI/Fake: 1.00\n"
          ]
        }
      ],
      "source": [
        "def predict_image_class(image_path):\n",
        "    # Preprocess the image\n",
        "    img_tensor = load_image(image_path).to(device)\n",
        "\n",
        "    # Extract features using the same CNNs\n",
        "    test_features_dict = {}\n",
        "    for name, model in cnn_models.items():\n",
        "        with torch.no_grad():\n",
        "            feat = model(img_tensor)\n",
        "            feat = feat.view(feat.size(0), -1)  # flatten\n",
        "            test_features_dict[name] = feat.cpu().numpy()\n",
        "\n",
        "    # Get predictions from each XGBoost model\n",
        "    probs = np.zeros(2)  # 2 classes: Real vs AI/Fake\n",
        "\n",
        "    for name, xgb_model in xgb_models.items():\n",
        "        probs += xgb_model.predict_proba(test_features_dict[name])[0]  # [0] because single sample\n",
        "\n",
        "    # Average probabilities (soft voting)\n",
        "    probs /= len(xgb_models)\n",
        "\n",
        "    # Final prediction\n",
        "    class_idx = np.argmax(probs)\n",
        "    class_names = ['Real', 'AI/Fake']\n",
        "\n",
        "    print(f\"Prediction for {image_path}: {class_names[class_idx]}\")\n",
        "    print(f\"Probabilities - Real: {probs[0]:.2f}, AI/Fake: {probs[1]:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbGh8WTn56qd"
      },
      "source": [
        "### Example usage with the function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09afLgUm55ou",
        "outputId": "01ce97ab-eec6-46bb-9f61-1905774d0672"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction for /content/drive/MyDrive/ML-Samples/try-test/01-ai.jpg: AI/Fake\n",
            "Probabilities - Real: 0.00, AI/Fake: 1.00\n",
            "Prediction for /content/drive/MyDrive/ML-Samples/try-test/01-real.jpg: Real\n",
            "Probabilities - Real: 0.95, AI/Fake: 0.05\n"
          ]
        }
      ],
      "source": [
        "# AI\n",
        "new_image_path = \"/content/drive/MyDrive/ INPUT DRIVE LOCATION\"\n",
        "predict_image_class(new_image_path)\n",
        "\n",
        "# REAL\n",
        "new_image_path = \"/content/drive/MyDrive/ INPUT DRIVE LOCATION\"\n",
        "predict_image_class(new_image_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZEH5HdzenA2"
      },
      "source": [
        "# WHOLE PYTHON PIPELINE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzZzFs8Aepma"
      },
      "outputs": [],
      "source": [
        "# 1️⃣ Install / Import Dependencies\n",
        "!pip install torch torchvision timm xgboost scikit-learn matplotlib seaborn\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import timm\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 2️⃣ Define dataset path\n",
        "dataset_path = \"/content/drive/MyDrive/ INPUT DRIVE LOCATION\"  # mount Google Drive first\n",
        "folders = [\"combined-total-legit\", \"combined-total-ai\"]  # your folders\n",
        "\n",
        "# 3️⃣ Image preprocessing\n",
        "image_size = 224  # standard input size\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((image_size, image_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 4️⃣ Load dataset\n",
        "# Create a unified dataset with labels: 0 = legit, 1 = AI\n",
        "data = []\n",
        "labels = []\n",
        "\n",
        "for idx, folder in enumerate(folders):\n",
        "    folder_path = os.path.join(dataset_path, folder)\n",
        "    for img_file in os.listdir(folder_path):\n",
        "        img_path = os.path.join(folder_path, img_file)\n",
        "        data.append(img_path)\n",
        "        labels.append(idx)\n",
        "\n",
        "print(f\"Total images: {len(data)}\")\n",
        "\n",
        "# 5️⃣ Helper function: load and preprocess image\n",
        "from PIL import Image\n",
        "\n",
        "def load_image(path):\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    return transform(img).unsqueeze(0)  # add batch dim\n",
        "\n",
        "# 6️⃣ Define CNN models (pretrained)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "cnn_models = {\n",
        "    \"resnet34\": models.resnet34(pretrained=True),\n",
        "    \"efficientnet_b0\": models.efficientnet_b0(pretrained=True),\n",
        "    \"mobilenet_v2\": models.mobilenet_v2(pretrained=True)\n",
        "}\n",
        "\n",
        "# Remove final classifier layers, keep feature extractor\n",
        "for name, model in cnn_models.items():\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    if \"resnet\" in name:\n",
        "        cnn_models[name] = nn.Sequential(*list(model.children())[:-1])\n",
        "    elif \"efficientnet\" in name or \"mobilenet\" in name:\n",
        "        cnn_models[name] = nn.Sequential(*list(model.children())[:-1])\n",
        "\n",
        "# 7️⃣ Extract features for all images\n",
        "def extract_features(model, data):\n",
        "    features = []\n",
        "    with torch.no_grad():\n",
        "        for path in data:\n",
        "            img_tensor = load_image(path).to(device)\n",
        "            feat = model(img_tensor)\n",
        "            feat = feat.view(feat.size(0), -1)  # flatten\n",
        "            features.append(feat.cpu().numpy()[0])\n",
        "    return np.array(features)\n",
        "\n",
        "features_dict = {}\n",
        "for name, model in cnn_models.items():\n",
        "    print(f\"Extracting features from {name}...\")\n",
        "    features_dict[name] = extract_features(model, data)\n",
        "\n",
        "# 8️⃣ Train XGBoost classifier per model\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_dict, X_test_dict, y_train, y_test = {}, {}, train_test_split(labels, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Since features_dict[name] is array, split features\n",
        "for name in cnn_models.keys():\n",
        "    X_train_dict[name], X_test_dict[name], y_train, y_test = train_test_split(features_dict[name], labels, test_size=0.2, random_state=42)\n",
        "\n",
        "xgb_models = {}\n",
        "for name in cnn_models.keys():\n",
        "    print(f\"Training XGBoost for {name} features...\")\n",
        "    model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "    model.fit(X_train_dict[name], y_train)\n",
        "    xgb_models[name] = model\n",
        "\n",
        "# 9️⃣ Ensemble prediction (soft voting)\n",
        "probs = np.zeros((len(y_test), len(folders)))  # num_samples x num_classes\n",
        "\n",
        "for name, model in xgb_models.items():\n",
        "    probs += model.predict_proba(X_test_dict[name])\n",
        "\n",
        "probs /= len(xgb_models)  # average probabilities\n",
        "y_pred = np.argmax(probs, axis=1)\n",
        "\n",
        "# 10️⃣ Evaluate\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Ensemble Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=folders, yticklabels=folders)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
